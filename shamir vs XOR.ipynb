{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892f7a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shamirs\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to split the secret into smaller chunks\n",
    "def split_secret(secret_int, chunk_size):\n",
    "    binary_str = bin(secret_int)[2:].zfill(chunk_size * ((len(bin(secret_int)[2:]) + chunk_size - 1) // chunk_size))\n",
    "    chunks = [int(binary_str[i:i + chunk_size], 2) for i in range(0, len(binary_str), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "# Function to combine shares for each chunk into a single share set\n",
    "def combine_shares(chunk_shares):\n",
    "    combined_shares = []\n",
    "    for i in range(len(chunk_shares[0])):\n",
    "        combined_shares.append(tuple(share[i] for share in chunk_shares))\n",
    "    return combined_shares\n",
    "\n",
    "# Function to apply Shamir's Secret Sharing to each chunk\n",
    "def shamir_split(secret_int, chunk_size, quantity, threshold):\n",
    "    chunks = split_secret(secret_int, chunk_size)\n",
    "    shares = [shamirs.shares(chunk, quantity=quantity, threshold=threshold) for chunk in chunks]\n",
    "    combined_shares = combine_shares(shares)\n",
    "    return combined_shares\n",
    "\n",
    "# Function to recover the original secret from shares\n",
    "def shamir_combine(shares, chunk_size):\n",
    "    chunks = [shamirs.interpolate(share_set) for share_set in zip(*shares)]\n",
    "    binary_str = ''.join(bin(chunk)[2:].zfill(chunk_size) for chunk in chunks)\n",
    "    return int(binary_str, 2)\n",
    "\n",
    "# Testing with the same loop as before\n",
    "iterations = 1\n",
    "\n",
    "# Arrays to store runtimes\n",
    "encoder_runtimes_shamir = []\n",
    "decoder_runtimes_shamir = []\n",
    "encoder_runtimes_xor = []\n",
    "decoder_runtimes_E1_E2 = []\n",
    "decoder_runtimes_E1_E3 = []\n",
    "decoder_runtimes_E2_E3 = []\n",
    "\n",
    "#secret = b\"This is the cryptography protocol\"\n",
    "with open('input.txt', 'rb') as f:\n",
    "    secret = f.read().strip()\n",
    "\n",
    "n = 3\n",
    "k = 2\n",
    "\n",
    "# Convert the secret to an integer\n",
    "secret_int = int.from_bytes(secret, byteorder='big')\n",
    "\n",
    "# Choose a chunk size that is smaller than the modulus (e.g., 32 bits)\n",
    "chunk_size = 32\n",
    "\n",
    "for _ in range(iterations):\n",
    "    # Shamir's Scheme\n",
    "    start_time = time.time()\n",
    "    shamir_shares = shamir_split(secret_int, chunk_size, quantity=n, threshold=k)\n",
    "    encoder_runtimes_shamir.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "    start_time = time.time()\n",
    "    recovered_secret_int = shamir_combine(shamir_shares, chunk_size)\n",
    "    decoder_runtimes_shamir.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "    # XOR-based Secret Sharing using bytes\n",
    "    start_time = time.time()\n",
    "    E1, E2, E3 = encode(secret_int)\n",
    "    encoder_runtimes_xor.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "    start_time = time.time()\n",
    "    decode(E1, E2, E1, E2, E3)\n",
    "    decoder_runtimes_E1_E2.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "    start_time = time.time()\n",
    "    decode(E1, E3, E1, E2, E3)\n",
    "    decoder_runtimes_E1_E3.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "    start_time = time.time()\n",
    "    decode(E2, E3, E1, E2, E3)\n",
    "    decoder_runtimes_E2_E3.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "# Calculating the averages\n",
    "avg_encoder_runtime_shamir = np.mean(encoder_runtimes_shamir)\n",
    "print(avg_encoder_runtime_shamir)\n",
    "avg_decoder_runtime_shamir = np.mean(decoder_runtimes_shamir)\n",
    "print(avg_decoder_runtime_shamir)\n",
    "avg_encoder_runtime_xor = np.mean(encoder_runtimes_xor)\n",
    "print(avg_encoder_runtime_xor)\n",
    "avg_decoder_runtime_E1_E2 = np.mean(decoder_runtimes_E1_E2)\n",
    "print(avg_decoder_runtime_E1_E2)\n",
    "avg_decoder_runtime_E1_E3 = np.mean(decoder_runtimes_E1_E3)\n",
    "print(avg_decoder_runtime_E1_E3)\n",
    "avg_decoder_runtime_E2_E3 = np.mean(decoder_runtimes_E2_E3)\n",
    "print(avg_decoder_runtime_E2_E3)\n",
    "\n",
    "# Calculate speedups\n",
    "encoder_speedup = avg_encoder_runtime_shamir / avg_encoder_runtime_xor\n",
    "decoder_speedup_E1_E2 = avg_decoder_runtime_shamir / avg_decoder_runtime_E1_E2\n",
    "decoder_speedup_E1_E3 = avg_decoder_runtime_shamir / avg_decoder_runtime_E1_E3\n",
    "decoder_speedup_E2_E3 = avg_decoder_runtime_shamir / avg_decoder_runtime_E2_E3\n",
    "\n",
    "print(f\"Encoder speedup (XOR vs Shamir): {encoder_speedup:.2f}x\")\n",
    "print(f\"Decoder speedup (E1,E2 vs Shamir): {decoder_speedup_E1_E2:.2f}x\")\n",
    "print(f\"Decoder speedup (E1,E3 vs Shamir): {decoder_speedup_E1_E3:.2f}x\")\n",
    "print(f\"Decoder speedup (E2,E3 vs Shamir): {decoder_speedup_E2_E3:.2f}x\")\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(14, 7), dpi=100)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(['Shamir', 'XOR'], [avg_encoder_runtime_shamir, avg_encoder_runtime_xor], color=['#1f77b4', '#ff7f0e'])\n",
    "plt.title('Average Encoding Runtime (2, 3)', fontsize=24)\n",
    "plt.ylabel('Time (microseconds)', fontsize=24)\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(['Shamir', 'E1,E2', 'E1,E3', 'E2,E3'],\n",
    "        [avg_decoder_runtime_shamir, avg_decoder_runtime_E1_E2, avg_decoder_runtime_E1_E3, avg_decoder_runtime_E2_E3],\n",
    "        color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "plt.title('Average Decoding Runtime (2, 3)', fontsize=24)\n",
    "plt.ylabel('Time (microseconds)', fontsize=24)\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotting the speedup\n",
    "plt.figure(figsize=(10, 7), dpi=100)\n",
    "plt.bar(['Encoder', 'E1,E2', 'E1,E3', 'E2,E3'],\n",
    "        [encoder_speedup, decoder_speedup_E1_E2, decoder_speedup_E1_E3, decoder_speedup_E2_E3],\n",
    "        color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "plt.title('Speedup of XOR-based Scheme Over Shamir\\'s Scheme', fontsize=24)\n",
    "plt.ylabel('Speedup Factor', fontsize=24)\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5144b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shamirs\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to split the secret into smaller chunks\n",
    "def split_secret(secret_int, chunk_size):\n",
    "    binary_str = bin(secret_int)[2:].zfill(chunk_size * ((len(bin(secret_int)[2:]) + chunk_size - 1) // chunk_size))\n",
    "    chunks = [int(binary_str[i:i + chunk_size], 2) for i in range(0, len(binary_str), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "# Function to combine shares for each chunk into a single share set\n",
    "def combine_shares(chunk_shares):\n",
    "    combined_shares = []\n",
    "    for i in range(len(chunk_shares[0])):\n",
    "        combined_shares.append(tuple(share[i] for share in chunk_shares))\n",
    "    return combined_shares\n",
    "\n",
    "# Function to apply Shamir's Secret Sharing to each chunk\n",
    "def shamir_split(secret_int, chunk_size, quantity, threshold):\n",
    "    chunks = split_secret(secret_int, chunk_size)\n",
    "    shares = [shamirs.shares(chunk, quantity=quantity, threshold=threshold) for chunk in chunks]\n",
    "    combined_shares = combine_shares(shares)\n",
    "    return combined_shares\n",
    "\n",
    "# Function to recover the original secret from shares\n",
    "def shamir_combine(shares, chunk_size):\n",
    "    chunks = [shamirs.interpolate(share_set) for share_set in zip(*shares)]\n",
    "    binary_str = ''.join(bin(chunk)[2:].zfill(chunk_size) for chunk in chunks)\n",
    "    return int(binary_str, 2)\n",
    "\n",
    "# XOR-based Secret Sharing using bytes\n",
    "def encode(secret):\n",
    "    M = bin(secret)[2:]\n",
    "    if len(M) % 2 != 0:\n",
    "        M += '0'\n",
    "    half_len = len(M) // 2\n",
    "    M1 = bin_str_to_bytes(M[:half_len])\n",
    "    M2 = bin_str_to_bytes(M[half_len:])\n",
    "    \n",
    "    R1 = random.randbytes(len(M1))\n",
    "    R2 = random.randbytes(len(M2))\n",
    "    \n",
    "    E1 = R1 + bytes(a ^ b for a, b in zip(M2, R2))\n",
    "    E2 = bytes(a ^ b for a, b in zip(M1, R1)) + R2\n",
    "    E3 = bytes(a ^ b for a, b in zip(M1, R2)) + bytes(a ^ b for a, b in zip(M2, R1))\n",
    "    \n",
    "    return E1, E2, E3\n",
    "\n",
    "def decode(part1, part2, E1, E2, E3):\n",
    "    half_len = len(part1) // 2\n",
    "\n",
    "    if part1 == E1 and part2 == E2:\n",
    "        R1 = part1[:half_len]\n",
    "        R2 = part2[half_len:]\n",
    "        M1 = bytes(a ^ b for a, b in zip(part2[:half_len], R1))\n",
    "        M2 = bytes(a ^ b for a, b in zip(part1[half_len:], R2))\n",
    "    elif part1 == E1 and part2 == E3:\n",
    "        R1 = part1[:half_len]\n",
    "        M2 = bytes(a ^ b for a, b in zip(part2[half_len:], R1))\n",
    "        R2 = bytes(a ^ b for a, b in zip(part1[half_len:], M2))\n",
    "        M1 = bytes(a ^ b for a, b in zip(part2[:half_len], R2))\n",
    "    elif part1 == E2 and part2 == E3:\n",
    "        R2 = part1[half_len:]\n",
    "        M1 = bytes(a ^ b for a, b in zip(part2[:half_len], R2))\n",
    "        R1 = bytes(a ^ b for a, b in zip(part1[:half_len], M1))\n",
    "        M2 = bytes(a ^ b for a, b in zip(part2[half_len:], R1))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid parts provided for decoding.\")\n",
    "\n",
    "    M = M1 + M2\n",
    "    return int.from_bytes(M, byteorder='big')\n",
    "\n",
    "# List of input files\n",
    "input_files = [\n",
    "    'input_1_bytes.txt',\n",
    "    'input_10_bytes.txt',\n",
    "    'input_100_bytes.txt',\n",
    "    'input_1000_bytes.txt',\n",
    "    'input_10000_bytes.txt'\n",
    "]\n",
    "\n",
    "# Arrays to store average runtimes across files\n",
    "avg_encoder_runtimes_shamir = []\n",
    "avg_decoder_runtimes_shamir = []\n",
    "avg_encoder_runtimes_xor = []\n",
    "avg_decoder_runtimes_E1_E2 = []\n",
    "avg_decoder_runtimes_E1_E3 = []\n",
    "avg_decoder_runtimes_E2_E3 = []\n",
    "\n",
    "n = 3  # Number of shares\n",
    "k = 2  # Threshold\n",
    "\n",
    "# Choose a chunk size that is smaller than the modulus (e.g., 32 bits)\n",
    "chunk_size = 32\n",
    "\n",
    "for input_file in input_files:\n",
    "    # Read the secret from the file\n",
    "    with open(input_file, 'rb') as f:\n",
    "        secret = f.read().strip()\n",
    "\n",
    "    # Convert the secret to an integer\n",
    "    secret_int = int.from_bytes(secret, byteorder='big')\n",
    "\n",
    "    # Arrays to store runtimes for this file\n",
    "    encoder_runtimes_shamir = []\n",
    "    decoder_runtimes_shamir = []\n",
    "    encoder_runtimes_xor = []\n",
    "    decoder_runtimes_E1_E2 = []\n",
    "    decoder_runtimes_E1_E3 = []\n",
    "    decoder_runtimes_E2_E3 = []\n",
    "\n",
    "    # Perform the encoding and decoding multiple times (iterations) for averaging\n",
    "    iterations = 10\n",
    "    for _ in range(iterations):\n",
    "        # Shamir's Scheme\n",
    "        start_time = time.time()\n",
    "        shamir_shares = shamir_split(secret_int, chunk_size, quantity=n, threshold=k)\n",
    "        encoder_runtimes_shamir.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "        start_time = time.time()\n",
    "        recovered_secret_int = shamir_combine(shamir_shares, chunk_size)\n",
    "        decoder_runtimes_shamir.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "        # XOR-based Secret Sharing using bytes\n",
    "        start_time = time.time()\n",
    "        E1, E2, E3 = encode(secret_int)\n",
    "        encoder_runtimes_xor.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "        start_time = time.time()\n",
    "        decode(E1, E2, E1, E2, E3)\n",
    "        decoder_runtimes_E1_E2.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "        start_time = time.time()\n",
    "        decode(E1, E3, E1, E2, E3)\n",
    "        decoder_runtimes_E1_E3.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "        start_time = time.time()\n",
    "        decode(E2, E3, E1, E2, E3)\n",
    "        decoder_runtimes_E2_E3.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "    # Calculating the averages for this file\n",
    "    avg_encoder_runtimes_shamir.append(np.mean(encoder_runtimes_shamir))\n",
    "    avg_decoder_runtimes_shamir.append(np.mean(decoder_runtimes_shamir))\n",
    "    avg_encoder_runtimes_xor.append(np.mean(encoder_runtimes_xor))\n",
    "    avg_decoder_runtimes_E1_E2.append(np.mean(decoder_runtimes_E1_E2))\n",
    "    avg_decoder_runtimes_E1_E3.append(np.mean(decoder_runtimes_E1_E3))\n",
    "    avg_decoder_runtimes_E2_E3.append(np.mean(decoder_runtimes_E2_E3))\n",
    "\n",
    "# Plotting the results as line graphs\n",
    "plt.figure(figsize=(14, 7), dpi=100)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(input_files, avg_encoder_runtimes_shamir, label='Shamir Encoder', marker='o', color='#1f77b4')\n",
    "plt.plot(input_files, avg_encoder_runtimes_xor, label='XOR Encoder', marker='o', color='#ff7f0e')\n",
    "plt.title('Average Encoding Runtime for Different Inputs', fontsize=24)\n",
    "plt.ylabel('Time (microseconds)', fontsize=24)\n",
    "plt.xticks(rotation=45, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(input_files, avg_decoder_runtimes_shamir, label='Shamir Decoder', marker='o', color='#1f77b4')\n",
    "plt.plot(input_files, avg_decoder_runtimes_E1_E2, label='E1,E2 Decoder', marker='o', color='#ff7f0e')\n",
    "plt.plot(input_files, avg_decoder_runtimes_E1_E3, label='E1,E3 Decoder', marker='o', color='#2ca02c')\n",
    "plt.plot(input_files, avg_decoder_runtimes_E2_E3, label='E2,E3 Decoder', marker='o', color='#d62728')\n",
    "plt.title('Average Decoding Runtime for Different Inputs', fontsize=24)\n",
    "plt.ylabel('Time (microseconds)', fontsize=24)\n",
    "plt.xticks(rotation=45, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3402f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shamirs\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to split the secret into smaller chunks\n",
    "def split_secret(secret_int, chunk_size):\n",
    "    binary_str = bin(secret_int)[2:].zfill(chunk_size * ((len(bin(secret_int)[2:]) + chunk_size - 1) // chunk_size))\n",
    "    chunks = [int(binary_str[i:i + chunk_size], 2) for i in range(0, len(binary_str), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "# Function to combine shares for each chunk into a single share set\n",
    "def combine_shares(chunk_shares):\n",
    "    combined_shares = []\n",
    "    for i in range(len(chunk_shares[0])):\n",
    "        combined_shares.append(tuple(share[i] for share in chunk_shares))\n",
    "    return combined_shares\n",
    "\n",
    "# Function to apply Shamir's Secret Sharing to each chunk\n",
    "def shamir_split(secret_int, chunk_size, quantity, threshold):\n",
    "    chunks = split_secret(secret_int, chunk_size)\n",
    "    shares = [shamirs.shares(chunk, quantity=quantity, threshold=threshold) for chunk in chunks]\n",
    "    combined_shares = combine_shares(shares)\n",
    "    return combined_shares\n",
    "\n",
    "# Function to recover the original secret from shares\n",
    "def shamir_combine(shares, chunk_size):\n",
    "    chunks = [shamirs.interpolate(share_set) for share_set in zip(*shares)]\n",
    "    binary_str = ''.join(bin(chunk)[2:].zfill(chunk_size) for chunk in chunks)\n",
    "    return int(binary_str, 2)\n",
    "\n",
    "# XOR-based Secret Sharing using bytes\n",
    "def encode(secret):\n",
    "    M = bin(secret)[2:]\n",
    "    if len(M) % 2 != 0:\n",
    "        M += '0'\n",
    "    half_len = len(M) // 2\n",
    "    M1 = M[:half_len].encode()\n",
    "    M2 = M[half_len:].encode()\n",
    "    \n",
    "    R1 = random.randbytes(len(M1))\n",
    "    R2 = random.randbytes(len(M2))\n",
    "    \n",
    "    E1 = R1 + bytes(a ^ b for a, b in zip(M2, R2))\n",
    "    E2 = bytes(a ^ b for a, b in zip(M1, R1)) + R2\n",
    "    E3 = bytes(a ^ b for a, b in zip(M1, R2)) + bytes(a ^ b for a, b in zip(M2, R1))\n",
    "    \n",
    "    return E1, E2, E3\n",
    "\n",
    "def decode(part1, part2, E1, E2, E3):\n",
    "    half_len = len(part1) // 2\n",
    "\n",
    "    if part1 == E1 and part2 == E2:\n",
    "        R1 = part1[:half_len]\n",
    "        R2 = part2[half_len:]\n",
    "        M1 = bytes(a ^ b for a, b in zip(part2[:half_len], R1))\n",
    "        M2 = bytes(a ^ b for a, b in zip(part1[half_len:], R2))\n",
    "    elif part1 == E1 and part2 == E3:\n",
    "        R1 = part1[:half_len]\n",
    "        M2 = bytes(a ^ b for a, b in zip(part2[half_len:], R1))\n",
    "        R2 = bytes(a ^ b for a, b in zip(part1[half_len:], M2))\n",
    "        M1 = bytes(a ^ b for a, b in zip(part2[:half_len], R2))\n",
    "    elif part1 == E2 and part2 == E3:\n",
    "        R2 = part1[half_len:]\n",
    "        M1 = bytes(a ^ b for a, b in zip(part2[:half_len], R2))\n",
    "        R1 = bytes(a ^ b for a, b in zip(part1[:half_len], M1))\n",
    "        M2 = bytes(a ^ b for a, b in zip(part2[half_len:], R1))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid parts provided for decoding.\")\n",
    "\n",
    "    M = M1 + M2\n",
    "    return int.from_bytes(M, byteorder='big')\n",
    "\n",
    "# List of input files\n",
    "input_files = [\n",
    "    'input_1_bytes.txt',\n",
    "    'input_10_bytes.txt',\n",
    "    'input_100_bytes.txt',\n",
    "    'input_1000_bytes.txt',\n",
    "    'input_10000_bytes.txt'\n",
    "]\n",
    "\n",
    "# Arrays to store average runtimes across files\n",
    "avg_encoder_runtimes_shamir = []\n",
    "avg_decoder_runtimes_shamir = []\n",
    "avg_encoder_runtimes_xor = []\n",
    "avg_decoder_runtimes_E1_E2 = []\n",
    "avg_decoder_runtimes_E1_E3 = []\n",
    "avg_decoder_runtimes_E2_E3 = []\n",
    "\n",
    "n = 3  # Number of shares\n",
    "k = 2  # Threshold\n",
    "\n",
    "# Choose a chunk size that is smaller than the modulus (e.g., 32 bits)\n",
    "chunk_size = 32\n",
    "\n",
    "for input_file in input_files:\n",
    "    # Read the secret from the file\n",
    "    with open(input_file, 'rb') as f:\n",
    "        secret = f.read().strip()\n",
    "\n",
    "    # Convert the secret to an integer\n",
    "    secret_int = int.from_bytes(secret, byteorder='big')\n",
    "\n",
    "    # Arrays to store runtimes for this file\n",
    "    encoder_runtimes_shamir = []\n",
    "    decoder_runtimes_shamir = []\n",
    "    encoder_runtimes_xor = []\n",
    "    decoder_runtimes_E1_E2 = []\n",
    "    decoder_runtimes_E1_E3 = []\n",
    "    decoder_runtimes_E2_E3 = []\n",
    "\n",
    "    # Perform the encoding and decoding multiple times (iterations) for averaging\n",
    "    iterations = 10\n",
    "    for _ in range(iterations):\n",
    "        # Shamir's Scheme\n",
    "        start_time = time.time()\n",
    "        shamir_shares = shamir_split(secret_int, chunk_size, quantity=n, threshold=k)\n",
    "        encoder_runtimes_shamir.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "        start_time = time.time()\n",
    "        recovered_secret_int = shamir_combine(shamir_shares, chunk_size)\n",
    "        decoder_runtimes_shamir.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "        # XOR-based Secret Sharing using bytes\n",
    "        start_time = time.time()\n",
    "        E1, E2, E3 = encode(secret_int)\n",
    "        encoder_runtimes_xor.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "        start_time = time.time()\n",
    "        decode(E1, E2, E1, E2, E3)\n",
    "        decoder_runtimes_E1_E2.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "        start_time = time.time()\n",
    "        decode(E1, E3, E1, E2, E3)\n",
    "        decoder_runtimes_E1_E3.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "        start_time = time.time()\n",
    "        decode(E2, E3, E1, E2, E3)\n",
    "        decoder_runtimes_E2_E3.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "    # Calculating the averages for this file\n",
    "    avg_encoder_runtimes_shamir.append(np.mean(encoder_runtimes_shamir))\n",
    "    avg_decoder_runtimes_shamir.append(np.mean(decoder_runtimes_shamir))\n",
    "    avg_encoder_runtimes_xor.append(np.mean(encoder_runtimes_xor))\n",
    "    avg_decoder_runtimes_E1_E2.append(np.mean(decoder_runtimes_E1_E2))\n",
    "    avg_decoder_runtimes_E1_E3.append(np.mean(decoder_runtimes_E1_E3))\n",
    "    avg_decoder_runtimes_E2_E3.append(np.mean(decoder_runtimes_E2_E3))\n",
    "\n",
    "# Print the calculated data\n",
    "print(\"Average Encoder Runtimes (Shamir):\", avg_encoder_runtimes_shamir)\n",
    "print(\"Average Decoder Runtimes (Shamir):\", avg_decoder_runtimes_shamir)\n",
    "print(\"Average Encoder Runtimes (XOR):\", avg_encoder_runtimes_xor)\n",
    "print(\"Average Decoder Runtimes (E1,E2):\", avg_decoder_runtimes_E1_E2)\n",
    "print(\"Average Decoder Runtimes (E1,E3):\", avg_decoder_runtimes_E1_E3)\n",
    "print(\"Average Decoder Runtimes (E2,E3):\", avg_decoder_runtimes_E2_E3)\n",
    "\n",
    "# Plotting the results as line graphs\n",
    "plt.figure(figsize=(14, 7), dpi=100)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(input_files, avg_encoder_runtimes_shamir, label='Shamir Encoder', marker='o', color='#1f77b4')\n",
    "plt.plot(input_files, avg_encoder_runtimes_xor, label='XOR Encoder', marker='o', color='#ff7f0e')\n",
    "plt.title('Average Encoding Runtime for Different Inputs', fontsize=24)\n",
    "plt.ylabel('Time (microseconds)', fontsize=24)\n",
    "plt.xticks(rotation=45, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(input_files, avg_decoder_runtimes_shamir, label='Shamir Decoder', marker='o', color='#1f77b4')\n",
    "plt.plot(input_files, avg_decoder_runtimes_E1_E2, label='E1,E2 Decoder', marker='o', color='#ff7f0e')\n",
    "plt.plot(input_files, avg_decoder_runtimes_E1_E3, label='E1,E3 Decoder', marker='o', color='#2ca02c')\n",
    "plt.plot(input_files, avg_decoder_runtimes_E2_E3, label='E2,E3 Decoder', marker='o', color='#d62728')\n",
    "plt.title('Average Decoding Runtime for Different Inputs', fontsize=24)\n",
    "plt.ylabel('Time (microseconds)', fontsize=24)\n",
    "plt.xticks(rotation=45, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311cbf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shamirs\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to split the secret into smaller chunks\n",
    "def split_secret(secret_int, chunk_size):\n",
    "    binary_str = bin(secret_int)[2:].zfill(chunk_size * ((len(bin(secret_int)[2:]) + chunk_size - 1) // chunk_size))\n",
    "    chunks = [int(binary_str[i:i + chunk_size], 2) for i in range(0, len(binary_str), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "# Function to combine shares for each chunk into a single share set\n",
    "def combine_shares(chunk_shares):\n",
    "    combined_shares = []\n",
    "    for i in range(len(chunk_shares[0])):\n",
    "        combined_shares.append(tuple(share[i] for share in chunk_shares))\n",
    "    return combined_shares\n",
    "\n",
    "# Function to apply Shamir's Secret Sharing to each chunk\n",
    "def shamir_split(secret_int, chunk_size, quantity, threshold):\n",
    "    chunks = split_secret(secret_int, chunk_size)\n",
    "    shares = [shamirs.shares(chunk, quantity=quantity, threshold=threshold) for chunk in chunks]\n",
    "    combined_shares = combine_shares(shares)\n",
    "    return combined_shares\n",
    "\n",
    "# Function to recover the original secret from shares\n",
    "def shamir_combine(shares, chunk_size):\n",
    "    chunks = [shamirs.interpolate(share_set) for share_set in zip(*shares)]\n",
    "    binary_str = ''.join(bin(chunk)[2:].zfill(chunk_size) for chunk in chunks)\n",
    "    return int(binary_str, 2)\n",
    "\n",
    "# XOR-based Secret Sharing using bytes\n",
    "def encode(secret):\n",
    "    M = bin(secret)[2:]\n",
    "    if len(M) % 2 != 0:\n",
    "        M += '0'\n",
    "    half_len = len(M) // 2\n",
    "    M1 = M[:half_len].encode()\n",
    "    M2 = M[half_len:].encode()\n",
    "    \n",
    "    R1 = random.randbytes(len(M1))\n",
    "    R2 = random.randbytes(len(M2))\n",
    "    \n",
    "    E1 = R1 + bytes(a ^ b for a, b in zip(M2, R2))\n",
    "    E2 = bytes(a ^ b for a, b in zip(M1, R1)) + R2\n",
    "    E3 = bytes(a ^ b for a, b in zip(M1, R2)) + bytes(a ^ b for a, b in zip(M2, R1))\n",
    "    \n",
    "    return E1, E2, E3\n",
    "\n",
    "def decode(part1, part2, E1, E2, E3):\n",
    "    half_len = len(part1) // 2\n",
    "\n",
    "    if part1 == E1 and part2 == E2:\n",
    "        R1 = part1[:half_len]\n",
    "        R2 = part2[half_len:]\n",
    "        M1 = bytes(a ^ b for a, b in zip(part2[:half_len], R1))\n",
    "        M2 = bytes(a ^ b for a, b in zip(part1[half_len:], R2))\n",
    "    elif part1 == E1 and part2 == E3:\n",
    "        R1 = part1[:half_len]\n",
    "        M2 = bytes(a ^ b for a, b in zip(part2[half_len:], R1))\n",
    "        R2 = bytes(a ^ b for a, b in zip(part1[half_len:], M2))\n",
    "        M1 = bytes(a ^ b for a, b in zip(part2[:half_len], R2))\n",
    "    elif part1 == E2 and part2 == E3:\n",
    "        R2 = part1[half_len:]\n",
    "        M1 = bytes(a ^ b for a, b in zip(part2[:half_len], R2))\n",
    "        R1 = bytes(a ^ b for a, b in zip(part1[:half_len], M1))\n",
    "        M2 = bytes(a ^ b for a, b in zip(part2[half_len:], R1))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid parts provided for decoding.\")\n",
    "\n",
    "    M = M1 + M2\n",
    "    return int.from_bytes(M, byteorder='big')\n",
    "\n",
    "# List of input files\n",
    "input_files = [\n",
    "    'input_1_bytes.txt',\n",
    "    'input_10_bytes.txt',\n",
    "    'input_100_bytes.txt',\n",
    "    'input_1000_bytes.txt',\n",
    "    'input_10000_bytes.txt'\n",
    "]\n",
    "\n",
    "# Arrays to store average runtimes across files\n",
    "avg_encoder_runtimes_shamir = []\n",
    "avg_decoder_runtimes_shamir = []\n",
    "avg_encoder_runtimes_xor = []\n",
    "avg_decoder_runtimes_E1_E2 = []\n",
    "avg_decoder_runtimes_E1_E3 = []\n",
    "avg_decoder_runtimes_E2_E3 = []\n",
    "\n",
    "n = 3  # Number of shares\n",
    "k = 2  # Threshold\n",
    "\n",
    "# Choose a chunk size that is smaller than the modulus (e.g., 32 bits)\n",
    "chunk_size = 32\n",
    "\n",
    "for input_file in input_files:\n",
    "    # Read the secret from the file\n",
    "    with open(input_file, 'rb') as f:\n",
    "        secret = f.read().strip()\n",
    "\n",
    "    # Convert the secret to an integer\n",
    "    secret_int = int.from_bytes(secret, byteorder='big')\n",
    "\n",
    "    # Arrays to store runtimes for this file\n",
    "    encoder_runtimes_shamir = []\n",
    "    decoder_runtimes_shamir = []\n",
    "    encoder_runtimes_xor = []\n",
    "    decoder_runtimes_E1_E2 = []\n",
    "    decoder_runtimes_E1_E3 = []\n",
    "    decoder_runtimes_E2_E3 = []\n",
    "\n",
    "    # Perform the encoding and decoding multiple times (iterations) for averaging\n",
    "    iterations = 10\n",
    "    for _ in range(iterations):\n",
    "        # Shamir's Scheme\n",
    "        start_time = time.time()\n",
    "        shamir_shares = shamir_split(secret_int, chunk_size, quantity=n, threshold=k)\n",
    "        encoder_runtimes_shamir.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "        start_time = time.time()\n",
    "        recovered_secret_int = shamir_combine(shamir_shares, chunk_size)\n",
    "        decoder_runtimes_shamir.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "        # XOR-based Secret Sharing using bytes\n",
    "        start_time = time.time()\n",
    "        E1, E2, E3 = encode(secret_int)\n",
    "        encoder_runtimes_xor.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "        start_time = time.time()\n",
    "        decode(E1, E2, E1, E2, E3)\n",
    "        decoder_runtimes_E1_E2.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "        start_time = time.time()\n",
    "        decode(E1, E3, E1, E2, E3)\n",
    "        decoder_runtimes_E1_E3.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "        start_time = time.time()\n",
    "        decode(E2, E3, E1, E2, E3)\n",
    "        decoder_runtimes_E2_E3.append((time.time() - start_time) * 1000000)  # Convert to microseconds\n",
    "\n",
    "    # Calculating the averages for this file\n",
    "    avg_encoder_runtimes_shamir.append(np.mean(encoder_runtimes_shamir))\n",
    "    avg_decoder_runtimes_shamir.append(np.mean(decoder_runtimes_shamir))\n",
    "    avg_encoder_runtimes_xor.append(np.mean(encoder_runtimes_xor))\n",
    "    avg_decoder_runtimes_E1_E2.append(np.mean(decoder_runtimes_E1_E2))\n",
    "    avg_decoder_runtimes_E1_E3.append(np.mean(decoder_runtimes_E1_E3))\n",
    "    avg_decoder_runtimes_E2_E3.append(np.mean(decoder_runtimes_E2_E3))\n",
    "\n",
    "# Print the calculated data\n",
    "print(\"Average Encoder Runtimes (Shamir):\", avg_encoder_runtimes_shamir)\n",
    "print(\"Average Decoder Runtimes (Shamir):\", avg_decoder_runtimes_shamir)\n",
    "print(\"Average Encoder Runtimes (XOR):\", avg_encoder_runtimes_xor)\n",
    "print(\"Average Decoder Runtimes (E1,E2):\", avg_decoder_runtimes_E1_E2)\n",
    "print(\"Average Decoder Runtimes (E1,E3):\", avg_decoder_runtimes_E1_E3)\n",
    "print(\"Average Decoder Runtimes (E2,E3):\", avg_decoder_runtimes_E2_E3)\n",
    "\n",
    "# Plotting the results as line graphs\n",
    "plt.figure(figsize=(14, 7), dpi=100)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(input_files, avg_encoder_runtimes_shamir, label='Shamir Encoder', marker='o', color='#1f77b4')\n",
    "plt.plot(input_files, avg_encoder_runtimes_xor, label='XOR Encoder', marker='o', color='#ff7f0e')\n",
    "plt.title('Average Encoding Runtime for Different Inputs', fontsize=24)\n",
    "plt.ylabel('Time (microseconds)', fontsize=24)\n",
    "plt.xticks(rotation=45, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(input_files, avg_decoder_runtimes_shamir, label='Shamir Decoder', marker='o', color='#1f77b4')\n",
    "plt.plot(input_files, avg_decoder_runtimes_E1_E2, label='E1,E2 Decoder', marker='o', color='#ff7f0e')\n",
    "plt.plot(input_files, avg_decoder_runtimes_E1_E3, label='E1,E3 Decoder', marker='o', color='#2ca02c')\n",
    "plt.plot(input_files, avg_decoder_runtimes_E2_E3, label='E2,E3 Decoder', marker='o', color='#d62728')\n",
    "plt.title('Average Decoding Runtime for Different Inputs', fontsize=24)\n",
    "plt.ylabel('Time (microseconds)', fontsize=24)\n",
    "plt.xticks(rotation=45, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cde9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data for the line graph\n",
    "input_sizes = ['1 byte', '10 bytes', '100 bytes', '1 KB', '10 KB']\n",
    "encoder_runtimes_shamir = [96.94099426269531, 34.57069396972656, 194.09656524658203, 1652.693748474121, 185192.03662872314]\n",
    "encoder_runtimes_xor = [5.53131103515625, 14.662742614746094, 120.47290802001953, 881.9580078125, 8423.900604248047]\n",
    "\n",
    "# Plotting the line graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.plot(input_sizes, encoder_runtimes_shamir, marker='o', linestyle='-', color='blue', label='Shamir')\n",
    "plt.plot(input_sizes, encoder_runtimes_xor, marker='o', linestyle='-', color='green', label='XOR')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Input Size', fontsize=20)\n",
    "plt.ylabel('Time (microseconds)', fontsize=20)\n",
    "plt.title('Encoder Runtimes for Various Input Sizes', fontsize=24)\n",
    "\n",
    "# Adding legend\n",
    "plt.legend(fontsize=16)\n",
    "\n",
    "# Adjusting the tick label size\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "# Setting a logarithmic scale for the y-axis\n",
    "plt.yscale('log')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b921435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the line graph with enhanced aesthetics\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plotting the Shamir line with enhancements\n",
    "plt.plot(input_sizes, encoder_runtimes_shamir, marker='o', linestyle='-', color='blue', \n",
    "         label='Shamir', markersize=10, linewidth=3)\n",
    "\n",
    "# Plotting the XOR line with enhancements\n",
    "plt.plot(input_sizes, encoder_runtimes_xor, marker='s', linestyle='--', color='green', \n",
    "         label='XOR', markersize=10, linewidth=3)\n",
    "\n",
    "# Adding labels and title with enhanced font styles\n",
    "plt.xlabel('Input Size', fontsize=22, fontweight='bold')\n",
    "plt.ylabel('Time (microseconds)', fontsize=22, fontweight='bold')\n",
    "plt.title('Encoder Runtimes for Various Input Sizes', fontsize=26, fontweight='bold')\n",
    "\n",
    "# Adding grid for better readability\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Adding legend with enhanced font size\n",
    "plt.legend(fontsize=18, loc='upper left')\n",
    "\n",
    "# Adjusting the tick label size and style\n",
    "plt.xticks(fontsize=18, fontweight='bold')\n",
    "plt.yticks(fontsize=18, fontweight='bold')\n",
    "\n",
    "# Setting a logarithmic scale for the y-axis\n",
    "plt.yscale('log')\n",
    "\n",
    "# Adding a custom background color\n",
    "plt.gca().set_facecolor('#f0f0f0')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed15f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data for the decoding time line graph\n",
    "input_sizes = ['1 byte', '10 bytes', '100 bytes', '1 KB', '10 KB']\n",
    "decoder_runtimes_shamir = [81.634521484375, 243.25847625732422, 2064.53800201416, 17870.450019836426, 168733.14380645752]\n",
    "decoder_runtimes_e1_e2 = [2.7179718017578125, 6.4849853515625, 40.0543212890625, 385.14137268066406, 3749.227523803711]\n",
    "decoder_runtimes_e1_e3 = [3.1948089599609375, 8.702278137207031, 60.820579528808594, 576.8060684204102, 5680.537223815918]\n",
    "decoder_runtimes_e2_e3 = [2.956390380859375, 8.749961853027344, 65.58895111083984, 579.0948867797852, 5722.332000732422]\n",
    "\n",
    "# Plotting the line graph with data labels for decoding times\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plotting the Shamir line\n",
    "plt.plot(input_sizes, decoder_runtimes_shamir, marker='o', linestyle='-', color='navy', \n",
    "         label='Shamir', markersize=8, linewidth=2)\n",
    "\n",
    "# Plotting the E1,E2 line\n",
    "plt.plot(input_sizes, decoder_runtimes_e1_e2, marker='s', linestyle='--', color='darkgreen', \n",
    "         label='E1,E2', markersize=8, linewidth=2)\n",
    "\n",
    "# Plotting the E1,E3 line\n",
    "plt.plot(input_sizes, decoder_runtimes_e1_e3, marker='^', linestyle=':', color='darkred', \n",
    "         label='E1,E3', markersize=8, linewidth=2)\n",
    "\n",
    "# Plotting the E2,E3 line\n",
    "plt.plot(input_sizes, decoder_runtimes_e2_e3, marker='d', linestyle='-.', color='purple', \n",
    "         label='E2,E3', markersize=8, linewidth=2)\n",
    "\n",
    "# Adding labels and title with professional font styles\n",
    "plt.xlabel('Input Size', fontsize=22)\n",
    "plt.ylabel('Time (microseconds)', fontsize=22)\n",
    "plt.title('Decoder Runtimes for Various Input Sizes', fontsize=24)\n",
    "\n",
    "# Adding data labels to the points\n",
    "for i, txt in enumerate(decoder_runtimes_shamir):\n",
    "    plt.text(input_sizes[i], txt, f'{txt:.2f}', fontsize=14, ha='right', va='bottom')\n",
    "\n",
    "for i, txt in enumerate(decoder_runtimes_e1_e2):\n",
    "    plt.text(input_sizes[i], txt, f'{txt:.2f}', fontsize=14, ha='left', va='bottom')\n",
    "\n",
    "for i, txt in enumerate(decoder_runtimes_e1_e3):\n",
    "    plt.text(input_sizes[i], txt, f'{txt:.2f}', fontsize=14, ha='left', va='top')\n",
    "\n",
    "for i, txt in enumerate(decoder_runtimes_e2_e3):\n",
    "    plt.text(input_sizes[i], txt, f'{txt:.2f}', fontsize=14, ha='right', va='top')\n",
    "\n",
    "# Adding a grid for clarity, but subtle\n",
    "plt.grid(True, which='both', linestyle='-', linewidth=0.7, alpha=0.7)\n",
    "\n",
    "# Adding legend with appropriate font size\n",
    "plt.legend(fontsize=16)\n",
    "\n",
    "# Adjusting the tick label size and style\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "\n",
    "# Setting a logarithmic scale for the y-axis\n",
    "plt.yscale('log')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
